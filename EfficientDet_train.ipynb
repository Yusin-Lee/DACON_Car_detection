{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cTHDyODENsgr"
   },
   "outputs": [],
   "source": [
    "# 라이브러리 및 모듈 import\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'NUM_CLASS':34,\n",
    "    'EPOCHS':10,\n",
    "    'ACCUMULATE':4,\n",
    "    'LR':3e-4,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SENfg9eZNsgu"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, annotation, data_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.coco = COCO(annotation)\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image = np.array(Image.open(os.path.join(self.data_dir, image_info['file_name'])).convert('RGB'))\n",
    "        image = A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3, p=0.8)(image=image)['image']\n",
    "        image = image.astype(np.float32) / 255.\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        labels = np.array([x['category_id'] for x in anns])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        areas = np.array([x['area'] for x in anns])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        is_crowds = np.array([x['iscrowd'] for x in anns])\n",
    "        is_crowds = torch.as_tensor(is_crowds, dtype=torch.int64)\n",
    "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([index]), 'area': areas,\n",
    "                  'iscrowd': is_crowds}\n",
    "        if self.transforms:\n",
    "            while True:\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:\n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    target['labels'] = torch.tensor(sample['labels'])\n",
    "                    break\n",
    "        return image, target, image_id\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "W8FQbYrjNsgx"
   },
   "outputs": [],
   "source": [
    "def train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        #A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3, p=0.8),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def valid_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Kc0uStKpNsgy"
   },
   "outputs": [],
   "source": [
    "# loss 추적\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kGjDutKiNsgy"
   },
   "outputs": [],
   "source": [
    "# https://github.com/rwightman/efficientdet-pytorch/blob/master/effdet/config/model_config.py\n",
    "def get_net(checkpoint_path=None):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d0')\n",
    "    config.num_classes = CFG['NUM_CLASS']\n",
    "    config.image_size = (512,512)\n",
    "    \n",
    "    config.soft_nms = False\n",
    "    config.max_det_per_image = 25\n",
    "    \n",
    "    net = EfficientDet(config, pretrained_backbone=True)\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes) \n",
    "    \n",
    "    if checkpoint_path:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return DetBenchTrain(net)\n",
    "    \n",
    "# train function\n",
    "def train_fn(num_epochs, train_loader, optimizer, scheduler, model, device, clip=35):\n",
    "    model.train()\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "            for images, targets, _ in tepoch:\n",
    "                tepoch.set_description(f'epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "                images = torch.stack(images) # bs, ch, w, h - 16, 3, 512, 512\n",
    "                images = images.to(device).float()\n",
    "                boxes = [target['boxes'].to(device).float() for target in targets]\n",
    "                labels = [target['labels'].to(device).float() for target in targets]\n",
    "                target = {\"bbox\": boxes, \"cls\": labels}\n",
    "\n",
    "                # calculate loss\n",
    "                loss, cls_loss, box_loss = model(images, target).values()\n",
    "                \n",
    "                # backward\n",
    "                (loss / CFG['ACCUMULATE']).backward()\n",
    "                \n",
    "                step += 1\n",
    "                if step % CFG['ACCUMULATE'] : \n",
    "                    continue\n",
    "                # grad clip\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "                tepoch.set_postfix({'LR':round(scheduler.get_lr()[0],6),'loss':float(loss.detach().cpu()), 'loss_bbox':float(box_loss.detach().cpu()), 'loss_cls':float(cls_loss.detach().cpu())})\n",
    "            \n",
    "            torch.save(model.state_dict(), f'./ckp/epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OS1UR7dqNsgz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annotation = './dataset/train.json'\n",
    "data_dir = './dataset/train'\n",
    "train_dataset = CustomDataset(annotation, data_dir, train_transform())\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "model = get_net()\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=CFG['LR'])\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, threshold_mode='abs', min_lr=1e-6, verbose=True)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer=optimizer, eta_min=1e-6, T_0=405, T_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# for images, targets, _ in tqdm(train_data_loader):\n",
    "#     labels += [target['labels'].tolist() for target in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]),\n",
       " array([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "        500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "        500, 500, 500, 500, 500, 500, 500, 500], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import itertools\n",
    "# output = list(itertools.chain(*labels))\n",
    "# np.unique(output,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1/10: 100%|██████████| 811/811 [10:10<00:00,  1.33batch/s, LR=0.000151, loss=1.19e+3, loss_bbox=0.00543, loss_cls=1.19e+3]\n",
      "epoch 2/10:  14%|█▎        | 111/811 [01:23<09:27,  1.23batch/s, LR=0.000119, loss=911, loss_bbox=0.00572, loss_cls=911]        "
     ]
    }
   ],
   "source": [
    "train_fn(CFG['EPOCHS'], train_data_loader, optimizer, scheduler, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL.Image as Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cv2\n",
    "# annotation = './dataset/train.json'\n",
    "# data_dir = './dataset/train'\n",
    "# coco = COCO(annotation)\n",
    "# transforms = A.Compose([A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4, p=0.8)]) #, A.HueSaturationValue(p = 1)\n",
    "\n",
    "# image_id = coco.getImgIds(imgIds=2)\n",
    "# image_info = coco.loadImgs(image_id)[0]\n",
    "\n",
    "# image = Image.open(os.path.join(data_dir, image_info['file_name'])).convert('RGB')\n",
    "# image = transforms(image = np.array(image))['image']\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EfficientDet_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
