{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GLb2lMFmNl8O"
   },
   "outputs": [],
   "source": [
    "# 라이브러리 및 모듈 import\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image, ImageDraw\n",
    "from utils import nms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_list, transform):\n",
    "        super().__init__()\n",
    "        self.img_list = img_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.img_list[idx]\n",
    "        img = Image.open(file_name).convert('RGB')\n",
    "        #img_size = torch.tensor(np.array(img).shape[:-1]).unsqueeze(0)\n",
    "        img = np.array(img).astype(np.float32) / 255.0\n",
    "        img = self.transform(image=np.array(img))['image']\n",
    "        return file_name, img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8XAO7td8Nl8d"
   },
   "outputs": [],
   "source": [
    "# Albumentation을 이용, augmentation 선언\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        A.Flip(p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = glob('./dataset/test/*.png')\n",
    "test_dataset = TestDataset(img_list, get_valid_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "R_XLukpXNl8e"
   },
   "outputs": [],
   "source": [
    "from effdet import DetBenchPredict\n",
    "import gc\n",
    "\n",
    "# Effdet config를 통해 모델 불러오기 + ckpt load\n",
    "def load_net(checkpoint_path, device):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d7')\n",
    "    config.num_classes = 35\n",
    "    config.image_size = (512,512)\n",
    "    \n",
    "    config.soft_nms = False\n",
    "    config.max_det_per_image = 25\n",
    "    \n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    net = DetBenchPredict(net)\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.eval()\n",
    "\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_box(box):\n",
    "    x1 = list(box)[0] * (1920/512)\n",
    "    y1 = list(box)[1] * (1080/512)\n",
    "    x2 = list(box)[2] * (1920/512)\n",
    "    y2 = list(box)[3] * (1080/512)\n",
    "    return x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 850/850 [05:52<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = f'./ckp/epoch_8.pth'\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = load_net(checkpoint_path, device)\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "results_csv = pd.read_csv('./dataset/sample_submission.csv')\n",
    "\n",
    "for file_names, image in tqdm(test_data_loader):\n",
    "    image = image.to(device).float()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    outputs = []\n",
    "    for out in output:\n",
    "        outputs.append({'boxes': out.detach().cpu().numpy()[:,:4], \n",
    "                        'scores': out.detach().cpu().numpy()[:,4], \n",
    "                        'labels': out.detach().cpu().numpy()[:,-1]})\n",
    "    \n",
    "    for file_name, output in zip(file_names, outputs):\n",
    "        file_name = file_name.split('\\\\')[1]\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        labels = []\n",
    "        for box, score, label  in zip(output['boxes'],output['scores'],output['labels']):\n",
    "            x1, y1, x2, y2 = denormalize_box(box)\n",
    "            score = score\n",
    "            label = label\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            scores.append(score)\n",
    "            labels.append(label)\n",
    "        picked_boxes, picked_score, picked_labels = nms(boxes, scores, labels, 0.5)\n",
    "\n",
    "        for box, score, label in zip(picked_boxes, picked_score, picked_labels):\n",
    "            if score < 0.3:\n",
    "                break\n",
    "            x1, y1, x2, y2 = box\n",
    "            score = score\n",
    "            label = label\n",
    "            results_csv.loc[len(results_csv.index)] = pd.Series({\"file_name\": file_name,\n",
    "            \"class_id\": int(label-1),\n",
    "            \"confidence\": score,\n",
    "            \"point1_x\": int(x1), \"point1_y\": int(y2),\n",
    "            \"point2_x\": int(x2), \"point2_y\": int(y2),\n",
    "            \"point3_x\": int(x2), \"point3_y\": int(y1),\n",
    "            \"point4_x\": int(x1), \"point4_y\": int(y1)})\n",
    "            # results_csv.loc[len(results_csv.index)] = pd.Series({\"file_name\": file_name,\n",
    "            # \"class_id\": label,\n",
    "            # \"confidence\": score,\n",
    "            # \"point1_x\": int(x1), \"point1_y\": int(y1),\n",
    "            # \"point2_x\": int(x2), \"point2_y\": int(y1),\n",
    "            # \"point3_x\": int(x2), \"point3_y\": int(y2),\n",
    "            # \"point4_x\": int(x1), \"point4_y\": int(y2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>point1_x</th>\n",
       "      <th>point1_y</th>\n",
       "      <th>point2_x</th>\n",
       "      <th>point2_y</th>\n",
       "      <th>point3_x</th>\n",
       "      <th>point3_y</th>\n",
       "      <th>point4_x</th>\n",
       "      <th>point4_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>064442001.png</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.73747</td>\n",
       "      <td>1126</td>\n",
       "      <td>495</td>\n",
       "      <td>1427</td>\n",
       "      <td>495</td>\n",
       "      <td>1427</td>\n",
       "      <td>180</td>\n",
       "      <td>1126</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>064507368.png</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.540124</td>\n",
       "      <td>487</td>\n",
       "      <td>424</td>\n",
       "      <td>751</td>\n",
       "      <td>424</td>\n",
       "      <td>751</td>\n",
       "      <td>131</td>\n",
       "      <td>487</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>065131036.png</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.832454</td>\n",
       "      <td>1092</td>\n",
       "      <td>314</td>\n",
       "      <td>1353</td>\n",
       "      <td>314</td>\n",
       "      <td>1353</td>\n",
       "      <td>52</td>\n",
       "      <td>1092</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>065131036.png</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.829599</td>\n",
       "      <td>817</td>\n",
       "      <td>824</td>\n",
       "      <td>1153</td>\n",
       "      <td>824</td>\n",
       "      <td>1153</td>\n",
       "      <td>425</td>\n",
       "      <td>817</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>065147868.png</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.745616</td>\n",
       "      <td>728</td>\n",
       "      <td>498</td>\n",
       "      <td>1008</td>\n",
       "      <td>498</td>\n",
       "      <td>1008</td>\n",
       "      <td>191</td>\n",
       "      <td>728</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>183928410.png</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.563135</td>\n",
       "      <td>678</td>\n",
       "      <td>312</td>\n",
       "      <td>907</td>\n",
       "      <td>312</td>\n",
       "      <td>907</td>\n",
       "      <td>52</td>\n",
       "      <td>678</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>183928410.png</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.520882</td>\n",
       "      <td>1087</td>\n",
       "      <td>330</td>\n",
       "      <td>1356</td>\n",
       "      <td>330</td>\n",
       "      <td>1356</td>\n",
       "      <td>31</td>\n",
       "      <td>1087</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>183928410.png</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.487272</td>\n",
       "      <td>700</td>\n",
       "      <td>224</td>\n",
       "      <td>1109</td>\n",
       "      <td>224</td>\n",
       "      <td>1109</td>\n",
       "      <td>47</td>\n",
       "      <td>700</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>183928410.png</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.454233</td>\n",
       "      <td>732</td>\n",
       "      <td>250</td>\n",
       "      <td>887</td>\n",
       "      <td>250</td>\n",
       "      <td>887</td>\n",
       "      <td>-40</td>\n",
       "      <td>732</td>\n",
       "      <td>-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>184121675.png</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.894067</td>\n",
       "      <td>862</td>\n",
       "      <td>867</td>\n",
       "      <td>1152</td>\n",
       "      <td>867</td>\n",
       "      <td>1152</td>\n",
       "      <td>549</td>\n",
       "      <td>862</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4546 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name class_id confidence point1_x point1_y point2_x point2_y   \n",
       "0     064442001.png     25.0    0.73747     1126      495     1427      495  \\\n",
       "1     064507368.png     29.0   0.540124      487      424      751      424   \n",
       "2     065131036.png     28.0   0.832454     1092      314     1353      314   \n",
       "3     065131036.png     20.0   0.829599      817      824     1153      824   \n",
       "4     065147868.png     29.0   0.745616      728      498     1008      498   \n",
       "...             ...      ...        ...      ...      ...      ...      ...   \n",
       "4541  183928410.png     26.0   0.563135      678      312      907      312   \n",
       "4542  183928410.png     23.0   0.520882     1087      330     1356      330   \n",
       "4543  183928410.png     26.0   0.487272      700      224     1109      224   \n",
       "4544  183928410.png     26.0   0.454233      732      250      887      250   \n",
       "4545  184121675.png     28.0   0.894067      862      867     1152      867   \n",
       "\n",
       "     point3_x point3_y point4_x point4_y  \n",
       "0        1427      180     1126      180  \n",
       "1         751      131      487      131  \n",
       "2        1353       52     1092       52  \n",
       "3        1153      425      817      425  \n",
       "4        1008      191      728      191  \n",
       "...       ...      ...      ...      ...  \n",
       "4541      907       52      678       52  \n",
       "4542     1356       31     1087       31  \n",
       "4543     1109       47      700       47  \n",
       "4544      887      -40      732      -40  \n",
       "4545     1152      549      862      549  \n",
       "\n",
       "[4546 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1164\n",
    "file_name = './dataset/test/'+ results_csv.file_name[index]\n",
    "img = Image.open(file_name)\n",
    "x1, y1, x2, y2 = results_csv.point1_x[index] ,results_csv.point1_y[index], results_csv.point2_x[index], results_csv.point3_y[index]\n",
    "\n",
    "draw = ImageDraw.Draw(img, \"RGBA\")\n",
    "draw.rectangle((x1,y1,x2,y2), outline='red', width=1)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_csv.to_csv('./result.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_csv = pd.read_csv('./result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_csv['class_id'] = results_csv['class_id']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "        26., 27., 28., 29., 30., 31., 32.]),\n",
       " array([ 37, 222,  92, 109,  14, 229, 109, 264, 199,  79, 211,  45, 286,\n",
       "         59,  75,  21, 110,  81,  65,  82, 102, 198, 262, 240,  11,  22,\n",
       "        209,  70, 320, 126, 244, 144, 209], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results_csv['class_id'],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3016\n",
    "file_name = './dataset/test/'+ results_csv.file_name[index]\n",
    "img = Image.open(file_name)\n",
    "x1, y1, x2, y2 = results_csv.point1_x[index] ,results_csv.point3_y[index], results_csv.point2_x[index], results_csv.point2_y[index]\n",
    "\n",
    "draw = ImageDraw.Draw(img, \"RGBA\")\n",
    "draw.rectangle((x1,y1,x2,y2), outline='red', width=1)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EfficientDet_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
